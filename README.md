# LogHub

Loghub is a pipeline log, close to [logstash](https://www.elastic.co/products/logstash "Collect, Enrich & Transport Data"). But it's
written in java for improved stability and performance.

Documentation is in the [wiki](https://github.com/fbacchella/LogHub/wiki).

It received events from external sources, process them and send them.

All components are organized in many pipeline that can be interconnect. A pipeline goes from one receiver source
that generate events, send through processor and forward them to a sender or another pipeline.

Receiver source uses decoders that takes bytes messages and generate a event from that.

Sender source uses decoders that take event and produce bytes message that are then send to the configured destination.

All of these five kind of operator (Receivers, Senders, Processors, Coders and Decoders) are java classes that can be derived for
custom usages.

## Availables plugins

| Type | Name | Description |
| ---- | ---- | --- |
| input | [udp](https://github.com/fbacchella/LogHub/wiki/Receivers#loghubreceiversudp) | Receive plain UDP messages. Example: syslog udp input |
| input | [tcp](https://github.com/fbacchella/LogHub/wiki/Receivers#loghubreceiverstcplinesstream) | Listen a TCP port, each line will be mapped to a message. Example: syslog tcp input |
| input | [snmp-trap](https://github.com/fbacchella/LogHub/wiki/Receivers#loghubreceiverssnmptrap) | Parse an UDP snmp trap message |
| input | [zmq](https://github.com/fbacchella/LogHub/wiki/Receivers#loghubreceiversudp) | Connect to zmq topic |
| input | [kafka](https://github.com/fbacchella/LogHub/wiki/Receivers#loghubreceiverskafka) | Subscribe to a kafka topic |
| input | [http](https://github.com/fbacchella/LogHub/wiki/Receivers#loghubreceivershttp) | Receive HTTP messages |
| sender | http | Send message to a JSON http endpoint | 
| sender | elasticsearch | Send message to an ES cluster | 
| sender | file | Write message to file |
| sender | ncsa | Send NCSA compliant message |
| sender | stdout | Write message to stdout, useful for debugging | 
| sender | udp | Send UDP message, like to another syslog server | 
| sender | zmq | Send ZMQ message on the topic topic/queue | 
| decoder | StringCoder | Can be used to convert a syslog message to a string |
| processor | [grok](https://github.com/fbacchella/LogHub/wiki/Examples) | Apply a grok pattern to the input message |

#  Example

For configuration it uses a [DSL](https://en.wikipedia.org/wiki/Domain-specific_language "Domain specific language") generated
using [antlr](http://www.antlr.org "ANother Tool for Language Recognition"). It's syntax is a strange mix of logstash configuration files,
java and a small tast of groovy. The exact grammar can be found at https://github.com/fbacchella/LogHub/blob/master/src/main/antlr4/loghub/Route.g4.

It look like:

    input {
        loghub.receivers.ZMQ {
            listen: "tcp://localhost:2120",
            decoder: loghub.decoders.Log4j
        }
    } | $main
    input {
        loghub.receivers.Udp {
            port: 2121
            decoder: loghub.decoders.Msgpack
        }
    } | $apache

    output $main | { loghub.senders.ElasticSearch }

    pipeline[apache] { loghub.processors.Geoip { datfilepath:"/user/local/share/GeoIP/GeoIP.dat", locationfield:"location", threads:4 } }
    pipeline[main] {
         loghub.processors.Log { threads: 2 }
        | event.logger_name == "jrds.starter.Timer" || event.info > 4 ? loghub.processors.Drop  : ( loghub.processors.ParseJson | loghub.processors.Groovy { script: "println event['logger_name']" } )
    }
    extensions: "/usr/share/loghub/plugins:/usr/share/loghub/scripts"

This configuration define two receivers, one that listen using 0MQ for log4j events. The other listen for msgpack encoded events on a udp port,
like  some that can be generated by [mod_log_net](https://github.com/fbacchella/mod_log_net "An UDP logger for Apache").

The events received on UDP are send to one pipeline called "apache". All the events are transfered to the default "main" pipeline after resolving location
from visitors.

The log4j events are directly send to the main pipeline, that does some magic treatment on it. Pay attention to the test. It will be evaluated as a groovy scripts.

A property called "extensions" is defined. It allows to define custom extensions folders that will be used to resolve scripts and added to the class path.

In the configuration file, all the agent are defined using directly the class name.

If needed, slow or CPU bound processor can be given more dedicated threads by specifying a specific number of threads. They will be still one processor class instance, but many threads will send events to it.
